{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI Embedding Extraction\n",
    "\n",
    "This notebook extracts embeddings from MRI data using a pretrained CNN backbone.\n",
    "\n",
    "**Data sources supported:**\n",
    "- Kaggle 2D MRI image datasets (JPG/PNG)\n",
    "- NACC volumetric MRI via S3 (NIfTI format)\n",
    "\n",
    "**Output:** Compressed `.npz` file with float16 embeddings saved to Google Drive.\n",
    "\n",
    "---\n",
    "\n",
    "**Instructions:**\n",
    "1. Select GPU runtime: Runtime → Change runtime type → T4 GPU\n",
    "2. Run all cells in order\n",
    "3. Embeddings will be saved to your Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mount Google Drive and clone the project repo\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "PROJECT_DIR = '/content/drive/MyDrive/alzheimer-research'\n",
    "os.makedirs(PROJECT_DIR, exist_ok=True)\n",
    "\n",
    "# Clone repo if not already present\n",
    "REPO_DIR = '/content/alzheimer-research'\n",
    "if not os.path.exists(REPO_DIR):\n",
    "    # Replace with your actual repo URL\n",
    "    !git clone https://github.com/YOUR_USERNAME/alzheimer-research.git {REPO_DIR}\n",
    "else:\n",
    "    !cd {REPO_DIR} && git pull\n",
    "\n",
    "os.chdir(REPO_DIR)\n",
    "!pip install -q -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, REPO_DIR)\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {device}')\n",
    "if torch.cuda.is_available():\n",
    "    print(f'GPU: {torch.cuda.get_device_name(0)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option A: Kaggle 2D MRI Images\n",
    "\n",
    "Download the Kaggle Alzheimer's multiclass dataset and extract embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download Kaggle dataset (set up kaggle.json first)\n",
    "# !pip install -q kaggle\n",
    "# !mkdir -p ~/.kaggle && cp /content/drive/MyDrive/kaggle.json ~/.kaggle/\n",
    "# !chmod 600 ~/.kaggle/kaggle.json\n",
    "# !kaggle datasets download -d aryansinghal10/alzheimers-multiclass-dataset-equal-and-augmented -p /tmp/mri_data\n",
    "# !unzip -q /tmp/mri_data/*.zip -d /tmp/mri_data/\n",
    "\n",
    "# OR: manually upload / specify the path to your data directory\n",
    "MRI_DATA_DIR = '/tmp/mri_data'  # Update this path\n",
    "\n",
    "# Expected structure:\n",
    "# /tmp/mri_data/\n",
    "#   NonDemented/\n",
    "#   VeryMildDemented/\n",
    "#   MildDemented/\n",
    "#   ModerateDemented/\n",
    "\n",
    "import os\n",
    "if os.path.exists(MRI_DATA_DIR):\n",
    "    for d in sorted(os.listdir(MRI_DATA_DIR)):\n",
    "        full = os.path.join(MRI_DATA_DIR, d)\n",
    "        if os.path.isdir(full):\n",
    "            count = len(os.listdir(full))\n",
    "            print(f'{d}: {count} images')\n",
    "else:\n",
    "    print(f'Data directory not found: {MRI_DATA_DIR}')\n",
    "    print('Please download the dataset first (uncomment the kaggle commands above).')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.mri_cnn import MRIResNet2D\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "# Label mapping: folder name -> ordinal CDR class\n",
    "LABEL_MAP = {\n",
    "    'NonDemented': 0,\n",
    "    'VeryMildDemented': 1,\n",
    "    'MildDemented': 2,\n",
    "    'ModerateDemented': 3,\n",
    "}\n",
    "\n",
    "# Image transform for 2D ResNet\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.Grayscale(num_output_channels=1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5]),\n",
    "])\n",
    "\n",
    "# Load model\n",
    "EMBED_DIM = 256\n",
    "model = MRIResNet2D(embed_dim=EMBED_DIM, pretrained=True).to(device)\n",
    "model.eval()\n",
    "print(f'MRI ResNet-2D loaded (embed_dim={EMBED_DIM})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract embeddings from 2D MRI images\n",
    "all_embeddings = []\n",
    "all_labels = []\n",
    "all_filenames = []\n",
    "\n",
    "for class_name, label in LABEL_MAP.items():\n",
    "    class_dir = os.path.join(MRI_DATA_DIR, class_name)\n",
    "    if not os.path.exists(class_dir):\n",
    "        print(f'Skipping {class_name}: directory not found')\n",
    "        continue\n",
    "\n",
    "    files = sorted(os.listdir(class_dir))\n",
    "    print(f'Processing {class_name} ({len(files)} images)...')\n",
    "\n",
    "    batch_images = []\n",
    "    batch_size = 64\n",
    "\n",
    "    for i, fname in enumerate(tqdm(files, desc=class_name)):\n",
    "        fpath = os.path.join(class_dir, fname)\n",
    "        try:\n",
    "            img = Image.open(fpath).convert('L')  # grayscale\n",
    "            img_tensor = transform(img)\n",
    "            batch_images.append(img_tensor)\n",
    "            all_labels.append(label)\n",
    "            all_filenames.append(fname)\n",
    "        except Exception as e:\n",
    "            print(f'Error loading {fname}: {e}')\n",
    "            continue\n",
    "\n",
    "        # Process in batches\n",
    "        if len(batch_images) >= batch_size:\n",
    "            batch = torch.stack(batch_images).to(device)\n",
    "            with torch.no_grad():\n",
    "                embs = model.extract_embedding(batch)\n",
    "            all_embeddings.append(embs.cpu().numpy())\n",
    "            batch_images = []\n",
    "\n",
    "    # Process remaining\n",
    "    if batch_images:\n",
    "        batch = torch.stack(batch_images).to(device)\n",
    "        with torch.no_grad():\n",
    "            embs = model.extract_embedding(batch)\n",
    "        all_embeddings.append(embs.cpu().numpy())\n",
    "        batch_images = []\n",
    "\n",
    "embeddings = np.concatenate(all_embeddings, axis=0)\n",
    "labels = np.array(all_labels)\n",
    "\n",
    "print(f'\\nExtracted {len(embeddings)} embeddings of dimension {embeddings.shape[1]}')\n",
    "for name, lbl in LABEL_MAP.items():\n",
    "    print(f'  {name}: {(labels == lbl).sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save compressed embeddings to Google Drive\n",
    "SAVE_DIR = os.path.join(PROJECT_DIR, 'data_embeddings')\n",
    "os.makedirs(SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Save embeddings as float16 for compression\n",
    "emb_path = os.path.join(SAVE_DIR, 'mri_embeddings.npz')\n",
    "np.savez_compressed(emb_path, embeddings=embeddings.astype(np.float16))\n",
    "print(f'Saved MRI embeddings to {emb_path}')\n",
    "print(f'File size: {os.path.getsize(emb_path) / 1024 / 1024:.2f} MB')\n",
    "\n",
    "# Save labels\n",
    "labels_path = os.path.join(SAVE_DIR, 'labels.csv')\n",
    "df = pd.DataFrame({\n",
    "    'filename': all_filenames,\n",
    "    'label': labels,\n",
    "    'class_name': [list(LABEL_MAP.keys())[l] for l in labels],\n",
    "})\n",
    "df.to_csv(labels_path, index=False)\n",
    "print(f'Saved labels to {labels_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Option B: NACC 3D MRI Volumes via S3\n",
    "\n",
    "Download NIfTI volumes from NACC S3 bucket and extract 3D embeddings.\n",
    "\n",
    "**Important:** Set your S3 credentials as environment variables, never hardcode them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install AWS CLI and nibabel for NIfTI loading\n",
    "!pip install -q boto3 nibabel\n",
    "\n",
    "import boto3\n",
    "from getpass import getpass\n",
    "\n",
    "# Securely input credentials (DO NOT hardcode)\n",
    "AWS_ACCESS_KEY = getpass('Enter AWS Access Key ID: ')\n",
    "AWS_SECRET_KEY = getpass('Enter AWS Secret Access Key: ')\n",
    "S3_BUCKET = 'adsp-phc-quickaccess'\n",
    "S3_PREFIX = 'investigator/'\n",
    "\n",
    "s3 = boto3.client(\n",
    "    's3',\n",
    "    aws_access_key_id=AWS_ACCESS_KEY,\n",
    "    aws_secret_access_key=AWS_SECRET_KEY,\n",
    ")\n",
    "\n",
    "# List available files\n",
    "response = s3.list_objects_v2(Bucket=S3_BUCKET, Prefix=S3_PREFIX, MaxKeys=20)\n",
    "if 'Contents' in response:\n",
    "    for obj in response['Contents']:\n",
    "        print(f\"{obj['Key']}  ({obj['Size'] / 1024 / 1024:.1f} MB)\")\n",
    "else:\n",
    "    print('No objects found. Check credentials and bucket/prefix.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "from scipy.ndimage import zoom\n",
    "from models.mri_cnn import MRIResNet3D\n",
    "\n",
    "# Load 3D model\n",
    "model_3d = MRIResNet3D(embed_dim=EMBED_DIM, pretrained=True).to(device)\n",
    "model_3d.eval()\n",
    "\n",
    "TARGET_SHAPE = (64, 128, 128)  # (D, H, W) for 3D ResNet input\n",
    "\n",
    "def preprocess_nifti(nifti_path):\n",
    "    \"\"\"Load and preprocess a NIfTI MRI volume.\"\"\"\n",
    "    img = nib.load(nifti_path)\n",
    "    data = img.get_fdata().astype(np.float32)\n",
    "\n",
    "    # Normalize to [0, 1]\n",
    "    data = (data - data.min()) / (data.max() - data.min() + 1e-8)\n",
    "\n",
    "    # Resize to target shape\n",
    "    factors = [t / s for t, s in zip(TARGET_SHAPE, data.shape)]\n",
    "    data = zoom(data, factors, order=1)\n",
    "\n",
    "    # Add batch and channel dims: (1, 1, D, H, W)\n",
    "    tensor = torch.tensor(data).unsqueeze(0).unsqueeze(0)\n",
    "    return tensor\n",
    "\n",
    "print('3D MRI model ready.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and process NACC MRI volumes\n",
    "# This cell downloads one volume at a time to minimize disk usage\n",
    "\n",
    "TEMP_DIR = '/tmp/nacc_mri'\n",
    "os.makedirs(TEMP_DIR, exist_ok=True)\n",
    "\n",
    "# List NIfTI files in the S3 bucket\n",
    "paginator = s3.get_paginator('list_objects_v2')\n",
    "nifti_keys = []\n",
    "for page in paginator.paginate(Bucket=S3_BUCKET, Prefix=S3_PREFIX):\n",
    "    for obj in page.get('Contents', []):\n",
    "        if obj['Key'].endswith(('.nii', '.nii.gz')):\n",
    "            nifti_keys.append(obj['Key'])\n",
    "\n",
    "print(f'Found {len(nifti_keys)} NIfTI files')\n",
    "\n",
    "nacc_embeddings = []\n",
    "nacc_ids = []\n",
    "\n",
    "for key in tqdm(nifti_keys[:100], desc='Processing NACC MRI'):  # Limit for demo\n",
    "    local_path = os.path.join(TEMP_DIR, os.path.basename(key))\n",
    "    try:\n",
    "        # Download\n",
    "        s3.download_file(S3_BUCKET, key, local_path)\n",
    "\n",
    "        # Preprocess and extract embedding\n",
    "        volume = preprocess_nifti(local_path).to(device)\n",
    "        with torch.no_grad():\n",
    "            emb = model_3d.extract_embedding(volume)\n",
    "        nacc_embeddings.append(emb.cpu().numpy())\n",
    "        nacc_ids.append(os.path.basename(key))\n",
    "\n",
    "        # Delete raw file immediately\n",
    "        os.remove(local_path)\n",
    "    except Exception as e:\n",
    "        print(f'Error processing {key}: {e}')\n",
    "        if os.path.exists(local_path):\n",
    "            os.remove(local_path)\n",
    "\n",
    "if nacc_embeddings:\n",
    "    nacc_emb_array = np.concatenate(nacc_embeddings, axis=0)\n",
    "    print(f'Extracted {len(nacc_emb_array)} NACC embeddings')\n",
    "\n",
    "    # Save\n",
    "    nacc_path = os.path.join(SAVE_DIR, 'nacc_mri_embeddings.npz')\n",
    "    np.savez_compressed(nacc_path, embeddings=nacc_emb_array.astype(np.float16), ids=nacc_ids)\n",
    "    print(f'Saved to {nacc_path} ({os.path.getsize(nacc_path) / 1024 / 1024:.2f} MB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleanup temp files\n",
    "import shutil\n",
    "if os.path.exists('/tmp/mri_data'):\n",
    "    shutil.rmtree('/tmp/mri_data')\n",
    "    print('Cleaned up /tmp/mri_data')\n",
    "if os.path.exists('/tmp/nacc_mri'):\n",
    "    shutil.rmtree('/tmp/nacc_mri')\n",
    "    print('Cleaned up /tmp/nacc_mri')\n",
    "\n",
    "print('Done! Embeddings saved to Google Drive.')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
