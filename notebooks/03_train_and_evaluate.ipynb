{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 — Train and Evaluate the Multi-Task System\n",
    "\n",
    "Two-phase training:\n",
    "- **Phase 1**: MRI encoder pretraining (ordinal CDR only, cross-sectional)\n",
    "- **Phase 2**: Full multi-task (ordinal + survival + alignment) with longitudinal data\n",
    "\n",
    "Supports checkpoint-resume across Colab sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os, sys\n",
    "PROJECT_DIR = '/content/drive/MyDrive/alzheimer-research'\n",
    "sys.path.insert(0, PROJECT_DIR)\n",
    "\n",
    "!pip install -q nibabel\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from config import Config\n",
    "from models import AlzheimerMultiTaskModel\n",
    "from data.nacc_dataset import NACCMRIDataset, NACCLongitudinalDataset\n",
    "from data.speech_dataset import SpeechEmbeddingDataset, SyntheticSpeechDataset\n",
    "from data.preprocessing import build_mri_augmentation\n",
    "from training import Phase1Trainer, Phase2Trainer\n",
    "\n",
    "cfg = Config()\n",
    "cfg.ensure_dirs()\n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Device: {DEVICE}')\n",
    "if DEVICE.type == 'cuda':\n",
    "    print(f'GPU: {torch.cuda.get_device_name()}')\n",
    "    print(f'Memory: {torch.cuda.get_device_properties(0).total_mem / 1e9:.1f} GB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data\n",
    "\n",
    "Set `USE_REAL_DATA = True` once the manifest CSV is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_REAL_DATA = False  # flip to True when data is ready\n",
    "\n",
    "MANIFEST_CSV = str(cfg.embedding_dir / 'nacc_mri_manifest.csv')\n",
    "SPEECH_NPZ = str(cfg.embedding_dir / 'speech_features.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AlzheimerMultiTaskModel.from_config(cfg)\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "print(f'Total parameters:     {total_params:,}')\n",
    "print(f'Trainable parameters: {trainable:,}')\n",
    "print(f'Model size (fp16):    {total_params * 2 / 1e6:.1f} MB')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Phase 1 — MRI Ordinal Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REAL_DATA:\n",
    "    train_ids = np.load(cfg.embedding_dir / 'train_subject_ids.npy', allow_pickle=True)\n",
    "    val_ids = np.load(cfg.embedding_dir / 'val_subject_ids.npy', allow_pickle=True)\n",
    "\n",
    "    aug = build_mri_augmentation(cfg)\n",
    "    train_ds = NACCMRIDataset(MANIFEST_CSV, cfg.mri_volume_shape, transform=aug, subject_ids=train_ids)\n",
    "    val_ds = NACCMRIDataset(MANIFEST_CSV, cfg.mri_volume_shape, subject_ids=val_ids)\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_ds, batch_size=cfg.phase1_batch_size,\n",
    "        shuffle=True, num_workers=cfg.num_workers, pin_memory=cfg.pin_memory,\n",
    "    )\n",
    "    val_loader = DataLoader(\n",
    "        val_ds, batch_size=cfg.phase1_batch_size,\n",
    "        shuffle=False, num_workers=cfg.num_workers, pin_memory=cfg.pin_memory,\n",
    "    )\n",
    "\n",
    "    p1_trainer = Phase1Trainer(model, train_loader, val_loader, cfg, DEVICE)\n",
    "    p1_results = p1_trainer.fit(resume=False)\n",
    "    print(f'Phase 1 best QWK: {p1_results[\"best_qwk\"]:.4f}')\n",
    "else:\n",
    "    print('Skipping Phase 1 — set USE_REAL_DATA = True when manifest is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Phase 2 — Multi-Task + Longitudinal + Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REAL_DATA:\n",
    "    mri_train_ds = NACCLongitudinalDataset(\n",
    "        MANIFEST_CSV, cfg.mri_volume_shape, transform=aug, subject_ids=train_ids,\n",
    "    )\n",
    "    mri_val_ds = NACCLongitudinalDataset(\n",
    "        MANIFEST_CSV, cfg.mri_volume_shape, subject_ids=val_ids,\n",
    "    )\n",
    "\n",
    "    mri_train_loader = DataLoader(\n",
    "        mri_train_ds, batch_size=cfg.phase2_mri_batch_size,\n",
    "        shuffle=True, num_workers=cfg.num_workers, pin_memory=cfg.pin_memory,\n",
    "    )\n",
    "    mri_val_loader = DataLoader(\n",
    "        mri_val_ds, batch_size=cfg.phase2_mri_batch_size,\n",
    "        shuffle=False, num_workers=cfg.num_workers, pin_memory=cfg.pin_memory,\n",
    "    )\n",
    "\n",
    "    # Speech (optional)\n",
    "    speech_train_loader, speech_val_loader = None, None\n",
    "    from pathlib import Path\n",
    "    if Path(SPEECH_NPZ).exists():\n",
    "        speech_ds = SpeechEmbeddingDataset(SPEECH_NPZ)\n",
    "        speech_train_loader = DataLoader(\n",
    "            speech_ds, batch_size=cfg.phase2_speech_batch_size,\n",
    "            shuffle=True, drop_last=True,\n",
    "        )\n",
    "\n",
    "    p2_trainer = Phase2Trainer(\n",
    "        model, mri_train_loader, mri_val_loader,\n",
    "        speech_train_loader, speech_val_loader, cfg, DEVICE,\n",
    "    )\n",
    "    p2_results = p2_trainer.fit(resume=False)\n",
    "    print(f'Phase 2 best QWK: {p2_results[\"best_qwk\"]:.4f}')\n",
    "else:\n",
    "    print('Skipping Phase 2 — set USE_REAL_DATA = True when data is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REAL_DATA:\n",
    "    from training.callbacks import CheckpointManager\n",
    "    from evaluation.metrics import compute_all_ordinal_metrics, optimize_thresholds\n",
    "    from evaluation.visualization import (\n",
    "        plot_learning_curves, plot_confusion_matrix, plot_calibration,\n",
    "    )\n",
    "    from sklearn.metrics import confusion_matrix as cm_func\n",
    "\n",
    "    # Load best model\n",
    "    ckpt_mgr = CheckpointManager(cfg.checkpoint_dir, prefix='phase2')\n",
    "    ckpt = ckpt_mgr.load(which='best')\n",
    "    model.load_state_dict(ckpt['model_state'])\n",
    "    model.to(DEVICE).eval()\n",
    "\n",
    "    # Test set evaluation\n",
    "    test_ids = np.load(cfg.embedding_dir / 'test_subject_ids.npy', allow_pickle=True)\n",
    "    test_ds = NACCLongitudinalDataset(\n",
    "        MANIFEST_CSV, cfg.mri_volume_shape, subject_ids=test_ids,\n",
    "    )\n",
    "    test_loader = DataLoader(test_ds, batch_size=cfg.phase2_mri_batch_size)\n",
    "\n",
    "    all_preds, all_labels, all_severity = [], [], []\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            out = model.forward_mri_multitask(\n",
    "                batch['volumes'].to(DEVICE),\n",
    "                batch['time_deltas'].to(DEVICE),\n",
    "                batch['lengths'].to(DEVICE),\n",
    "            )\n",
    "            preds = (out['ord_cum_logits'] > 0).sum(dim=1).cpu()\n",
    "            all_preds.append(preds)\n",
    "            all_labels.append(batch['label'])\n",
    "            all_severity.append(out['ord_severity'].cpu())\n",
    "\n",
    "    preds = torch.cat(all_preds).numpy()\n",
    "    labels = torch.cat(all_labels).numpy()\n",
    "    severity = torch.cat(all_severity).squeeze().numpy()\n",
    "\n",
    "    # Post-hoc threshold optimisation\n",
    "    best_thresholds, opt_qwk = optimize_thresholds(severity, labels)\n",
    "    print(f'Optimised thresholds: {best_thresholds}')\n",
    "    print(f'Post-hoc QWK: {opt_qwk:.4f}')\n",
    "\n",
    "    # Full metrics\n",
    "    metrics = compute_all_ordinal_metrics(labels, preds)\n",
    "    for k, v in metrics.items():\n",
    "        print(f'  {k}: {v:.4f}')\n",
    "\n",
    "    # Plots\n",
    "    plot_learning_curves(p2_results['history'], cfg.results_dir / 'learning_curves.png')\n",
    "    cm = cm_func(labels, preds)\n",
    "    plot_confusion_matrix(cm, list(cfg.class_names), cfg.results_dir / 'confusion_matrix.png')\n",
    "    print(f'Plots saved to {cfg.results_dir}')\n",
    "else:\n",
    "    print('Skipping evaluation — set USE_REAL_DATA = True when data is ready')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Sanity Check (Synthetic Forward Pass)\n",
    "\n",
    "Verify the entire model runs end-to-end with random tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== Sanity check: forward pass with random data ===')\n",
    "model_test = AlzheimerMultiTaskModel.from_config(cfg).to(DEVICE)\n",
    "\n",
    "# Phase 1 forward\n",
    "fake_vol = torch.randn(2, 1, *cfg.mri_volume_shape, device=DEVICE)\n",
    "with torch.amp.autocast('cuda', enabled=cfg.use_amp and DEVICE.type == 'cuda'):\n",
    "    out1 = model_test.forward_phase1(fake_vol)\n",
    "print(f'Phase 1 output keys: {list(out1.keys())}')\n",
    "print(f'  severity shape: {out1[\"severity\"].shape}')\n",
    "print(f'  cum_logits shape: {out1[\"cum_logits\"].shape}')\n",
    "\n",
    "# Phase 2 forward (longitudinal)\n",
    "fake_seq = torch.randn(2, 3, 1, *cfg.mri_volume_shape, device=DEVICE)\n",
    "fake_dt = torch.tensor([[0, 12, 24], [0, 6, 0]], dtype=torch.float32, device=DEVICE)\n",
    "fake_lengths = torch.tensor([3, 2], device=DEVICE)\n",
    "\n",
    "with torch.amp.autocast('cuda', enabled=cfg.use_amp and DEVICE.type == 'cuda'):\n",
    "    out2 = model_test.forward_mri_multitask(\n",
    "        fake_seq, fake_dt, fake_lengths, run_survival=True,\n",
    "    )\n",
    "print(f'\\nPhase 2 output keys: {list(out2.keys())}')\n",
    "print(f'  embedding shape: {out2[\"embedding\"].shape}')\n",
    "print(f'  survival probs shape: {out2[\"surv_survival\"].shape}')\n",
    "\n",
    "# Speech forward\n",
    "fake_speech = torch.randn(4, cfg.speech_input_dim, device=DEVICE)\n",
    "with torch.amp.autocast('cuda', enabled=cfg.use_amp and DEVICE.type == 'cuda'):\n",
    "    out3 = model_test.forward_speech(fake_speech)\n",
    "print(f'\\nSpeech output keys: {list(out3.keys())}')\n",
    "print(f'  embedding shape: {out3[\"embedding\"].shape}')\n",
    "\n",
    "del model_test\n",
    "if DEVICE.type == 'cuda':\n",
    "    torch.cuda.empty_cache()\n",
    "print('\\nSanity check passed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
